Порядок действий для развертывания проекта на Airflow с использованием Docker Compose:

1. Клонировать проект с GitHub: Убедитесь, что у вас установлены Docker и Docker Compose.
Склонируйте репозиторий проекта с помощью команды git clone https://github.com/plhsh/reconciliation_demo.git

2. Перейти в корневую директорию проекта:
Перейдите в директорию, содержащую docker-compose.yaml файл вашего проекта, используя команду cd <имя_директории>
(например cd reconciliation_demo)

3. Запуск инициализации Airflow:
Выполните docker-compose up airflow-init для инициализации базы данных Airflow.
Это создаст необходимые таблицы и пользователя по умолчанию.
Этот шаг нужно выполнить один раз перед первым запуском Airflow.

4. Запуск всех сервисов:
Используйте команду docker compose up для запуска всех сервисов, определенных в docker-compose.yaml.
Если вы хотите запустить сервисы в фоновом режиме, используйте docker compose up -d.

5. Доступ к веб-интерфейсу Airflow:
После запуска всех сервисов веб-интерфейс Airflow будет доступен по адресу http://localhost:8080.
Используйте стандартные учетные данные для входа (airflow, airflow), если вы не задали свои собственные.

6. Добавьте json файлы из задания в папку dags\data\json_true_inbox

7. Укажите имейл адрес и пароль в email_config.py (тестирование проводилось с помощью почтового ящика outlook.com).
Отправьте на имейл письмо с файлом xlsx из задания.

8. На вкладке DAGs можно будет увидеть json_init_db_dag и xlsx_init_db_dag.
Они автоматически выполняются для инициализации бд единократно.

9. json_etl_dag и xlsx_etl_dag могут выполняться ежедневно по расписанию или вручную.
Каждый из этих ETL пайпов состоит из двух задач: получение фала с данными и запись данных в бд.
Полученные файлы после обработки перименовываюьтся и перемещаются согласно заданию.

10. БД PostgreSQL запускается как отдельный сервис в докер контейнере.
Данные для подключения можно посмотреть bd_config.py

